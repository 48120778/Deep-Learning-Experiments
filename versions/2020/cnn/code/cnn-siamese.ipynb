{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implements a Siamese/Y-Network using Functional API\n",
    "\n",
    "This is our first example of a network with a more complex graph. We call is Y-Network because it has a shape the is similar to the letter Y. There are two branches, left and right. Each one gets the same copy of input. Each branch processes the input and produces a different set of features. The left and right feature maps are the combined and passed to a head `Dense` layer for logistic regression. \n",
    "\n",
    "We use the same optimizer (`sgd`) and loss function (`categorical_crossentropy`). We train the network for 20 epochs.  \n",
    "\n",
    "~99.4% test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# from sparse label to categorical\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# reshape and normalize input images\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Branch of a Y-Network\n",
    "\n",
    "The left branch is made of 3 layers of CNN with increasing (doubling) number of feature maps: `Conv2D(32)-Conv2D(64)-Conv2D(128)`. To save in space, the left branch is constructed using a `for` loop. This technique and is used in constructing bigger models such as ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left branch of Y network\n",
    "left_inputs = Input(shape=input_shape)\n",
    "x = left_inputs\n",
    "# 3 layers of Conv2D-MaxPooling2D\n",
    "# number of filters doubles after each layer (32-64-128)\n",
    "for i in range(3):\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               padding='same',\n",
    "               activation='relu')(x)\n",
    "    #x = Dropout(dropout)(x)\n",
    "    x = MaxPooling2D()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Branch of a Y-Network\n",
    "\n",
    "The right branch is an exact mirror of the left branch. To ensure that it learns a different set of features, we use `dilation_rate = 2` to approximate a kernel with twice the size as the left brancg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right branch of Y network\n",
    "right_inputs = Input(shape=input_shape)\n",
    "y = right_inputs\n",
    "# 3 layers of Conv2D-Dropout-MaxPooling2D\n",
    "# number of filters doubles after each layer (32-64-128)\n",
    "for i in range(3):\n",
    "    y = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               padding='same',\n",
    "               activation='relu',\n",
    "               dilation_rate=2)(y)\n",
    "    #y = Dropout(dropout)(y)\n",
    "    y = MaxPooling2D()(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the 2 Branches\n",
    "\n",
    "To complete a Y-Network, let us merge the outputs of left and right branches. We use `concatenate()` which results to feature maps with the same dimension as left or right branch feature maps but with twice the number. There are other merging functions in Keras such as `add` and `multiply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Y_Network\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 64)   640         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 64)   640         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 14, 14, 64)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling2D) (None, 14, 14, 64)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 64)   36928       max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 64)   36928       max_pooling2d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 64)     36928       max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 64)     36928       max_pooling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D) (None, 3, 3, 64)     0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, 3, 3, 64)     0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 3, 3, 128)    0           max_pooling2d_32[0][0]           \n",
      "                                                                 max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1152)         0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           11530       flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 160,522\n",
      "Trainable params: 160,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# merge left and right branches outputs\n",
    "y = concatenate([x, y])\n",
    "# feature maps to vector in preparation to connecting to Dense layer\n",
    "y = Flatten()(y)\n",
    "# y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels, activation='softmax')(y)\n",
    "\n",
    "# build the model in functional API\n",
    "model = Model([left_inputs, right_inputs], outputs, name='Y_Network')\n",
    "# verify the model using graph\n",
    "# plot_model(model, to_file='cnn-y-network.png', show_shapes=True)\n",
    "# verify the model using layer text description\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Validation\n",
    "\n",
    "This is just our usual model training and validation. Similar to our previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 115s 245ms/step - loss: 1.9488 - accuracy: 0.4759 - val_loss: 0.8161 - val_accuracy: 0.7706\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 117s 249ms/step - loss: 0.4594 - accuracy: 0.8615 - val_loss: 0.2740 - val_accuracy: 0.9210\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 112s 238ms/step - loss: 0.2393 - accuracy: 0.9276 - val_loss: 0.1795 - val_accuracy: 0.9463\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 113s 240ms/step - loss: 0.1726 - accuracy: 0.9480 - val_loss: 0.1449 - val_accuracy: 0.9537\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 116s 247ms/step - loss: 0.1428 - accuracy: 0.9568 - val_loss: 0.1232 - val_accuracy: 0.9618\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 116s 248ms/step - loss: 0.1211 - accuracy: 0.9628 - val_loss: 0.1008 - val_accuracy: 0.9680\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 110s 235ms/step - loss: 0.1073 - accuracy: 0.9674 - val_loss: 0.0949 - val_accuracy: 0.9701\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 119s 253ms/step - loss: 0.0975 - accuracy: 0.9700 - val_loss: 0.0908 - val_accuracy: 0.9686\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 113s 241ms/step - loss: 0.0893 - accuracy: 0.9723 - val_loss: 0.0762 - val_accuracy: 0.9757\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 111s 236ms/step - loss: 0.0832 - accuracy: 0.9743 - val_loss: 0.0727 - val_accuracy: 0.9760\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 122s 261ms/step - loss: 0.0781 - accuracy: 0.9755 - val_loss: 0.0669 - val_accuracy: 0.9791\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 114s 244ms/step - loss: 0.0731 - accuracy: 0.9777 - val_loss: 0.0624 - val_accuracy: 0.9797\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 115s 246ms/step - loss: 0.0690 - accuracy: 0.9789 - val_loss: 0.0598 - val_accuracy: 0.9812\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 109s 232ms/step - loss: 0.0656 - accuracy: 0.9796 - val_loss: 0.0652 - val_accuracy: 0.9801\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 107s 229ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.0700 - val_accuracy: 0.9777\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 108s 231ms/step - loss: 0.0602 - accuracy: 0.9815 - val_loss: 0.0608 - val_accuracy: 0.9802\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 113s 240ms/step - loss: 0.0572 - accuracy: 0.9821 - val_loss: 0.0597 - val_accuracy: 0.9818\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 111s 236ms/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.0522 - val_accuracy: 0.9823\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 111s 238ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 0.0548 - val_accuracy: 0.9814\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 107s 228ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.0536 - val_accuracy: 0.9828\n",
      "79/79 [==============================] - 6s 70ms/step - loss: 0.0536 - accuracy: 0.9828\n",
      "\n",
      "Test accuracy: 98.3%\n"
     ]
    }
   ],
   "source": [
    "# classifier loss, Adam optimizer, classifier accuracy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model with input images and labels\n",
    "model.fit([x_train, x_train],\n",
    "          y_train, \n",
    "          validation_data=([x_test, x_test], y_test),\n",
    "          epochs=20,\n",
    "          batch_size=batch_size)\n",
    "\n",
    "# model accuracy on test dataset\n",
    "score = model.evaluate([x_test, x_test], y_test, batch_size=batch_size)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
